% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/GibbsBvsF.R
\name{GibbsBvsF}
\alias{GibbsBvsF}
\title{Bayesian Variable Selection with Factors for linear regression models using Gibbs
sampling.}
\usage{
GibbsBvsF(formula, data, null.model = paste(as.formula(formula)[[2]],
  " ~ 1", sep = ""), prior.betas = "Robust", prior.models = "SBSB2",
  n.iter = 10000, init.model = "Full", n.burnin = 500, n.thin = 1,
  time.test = TRUE, priorprobs = NULL, seed = runif(1, 0, 16091956))
}
\arguments{
\item{formula}{Formula defining the most complex regression model in the
analysis. See details.}

\item{data}{data frame containing the data.}

\item{null.model}{A formula defining which is the simplest (null) model.
It should be nested in the full model. It is compulsory that the null model
contains the intercept and by default, the null model is defined
to be the one with just the intercept}

\item{prior.betas}{Prior distribution for regression parameters within each
model. Possible choices include "Robust", "Liangetal", "gZellner",
and "ZellnerSiow" (see details).}

\item{prior.models}{Prior distribution over the model space. Possible
choices (see details) are "Const", "SB", "ConstConst" and "SBSB" (the default).}

\item{n.iter}{The total number of iterations performed after the burn in
process.}

\item{init.model}{The model at which the simulation process starts. Options
include "Null" (the model only with the covariates specified in
\code{fixed.cov}), "Full" (the model defined by \code{formula}), "Random" (a
randomly selected model) and a vector with p (the number of covariates to
select from) zeros and ones defining a model.}

\item{n.burnin}{Length of burn in, i.e. number of iterations to discard at
the beginning.}

\item{n.thin}{Thinning rate. Must be a positive integer.  Set 'n.thin' > 1
to save memory and computation time if 'n.iter' is large. Default is 1. This
parameter jointly with \code{n.iter} sets the number of simulations kept and
used to construct the estimates so is important to keep in mind that a large
value for 'n.thin' can reduce the precision of the results}

\item{time.test}{If TRUE and the number of variables is large (>=21) a
preliminary test to estimate computational time is performed.}

\item{priorprobs}{A p+1 dimensional vector defining the prior probabilities
Pr(M_i) (should be used in the case where \code{prior.models}="User"; see
the details in \code{\link[BayesVarSel]{Bvs}}.)}

\item{seed}{A seed to initialize the random number generator}
}
\value{
\code{GibbsBvs} returns an object of class \code{Bvs} with the
following elements: \item{time }{The internal time consumed in solving the
problem} \item{lmfull }{The \code{lm} class object that results when the
model defined by \code{formula} is fitted by \code{lm}} \item{lmnull }{The
\code{lm} class object that results when the model defined by
\code{fixed.cov} is fitted by \code{lm}} \item{variables }{The name of all
the potential explanatory variables} \item{n }{Number of observations}
\item{p }{Number of explanatory variables (both numerical and factors) to select from} \item{k }{Number
of fixed variables} \item{HPMbin }{The binary expression of the most
probable model found.} \item{inclprob }{A \code{data.frame} with the
estimates of the inclusion probabilities of all the variables.}
\item{jointinclprob }{A \code{data.frame} with the estimates of the joint
inclusion probabilities of all the variables.} \item{postprobdim }{Estimates
of posterior probabilities of the dimension of the true model.}
\item{modelslogBF}{A matrix with both the binary representation of the
visited models after the burning period and the Bayes factor (log scale) of
that model to the null model.}\item{priorprobs}{A p+1 dimensional vector containing values proportionals
to the prior probability of a model of each dimension (from 0 to p)} \item{call }{The \code{call} to the
function.}
\item{C}{An estimation of the normalizing constant (C=sum Bi Pr(Mi), for Mi in the model space) using the method in George and McCulloch (1997).}
\item{method }{\code{gibbs}}
}
\description{
Wersion of \code{\link[BayesVarSel]{GibbsBvs}} when the competing
variables contain factors. Results are presented as if the factors were
just another variable (independendtly on the number of levels) altough 
internally their treatment is quite more complex.
}
\details{
The methodology implemented in \code{GibbsBvsF} 
has been proposed in Garcia-Donato and Paulo (2019). Internally, a rank defficient representation
of factors using dummies is used and the number of competing models considered is

2^(pnum+sum_j l_j),

where pnum is the number of numerical variables and l_j is the number of levels in factor j. This
method leads to results that do not depend on how the factors are
coded (eg. via \code{\link[stats]{contr.treatment}}).

A main difference with \code{Bvs} and \code{GibbsBvs} concerns the prior
probabilities on the model space. In the presence of factors, this assignment
should take into account the "grouped" nature of the dummy variables representing
each factor.

The options \code{prior.models="SBSB"} and \code{prior.models="ConstConst"} use a two stage
prior. The first stage corresponds to factors and numerical variables and (conditional on these) a second
part of the prior specifies how probablities are apportioned over the different submodels defined
by the dummies. The default option is "SBSB" which uses in both stages an assignment
'a la' Scott-Berger so inversely proportional to the number of models of the same dimension. The
option "ConstConst" implements a uniform prior for both stages. The options \code{prior.models="Const"} and 
\code{prior.models="SB"} do not have a staged structure and "Const" apportions the prior probabilities
uniformly over all possible models (2^(p+sum_j l_j)) and in "SB" the probability
is inversely proportional to the number of any model of the same dimension.
}
\examples{

\dontrun{
data(diabetes, package="faraway")

#remove NA's and the column with the id of samples:
diabetes2<- na.omit(diabetes)[,-1]

#For reproducibility:
set.seed(16091956)
#Now run the main instruction
diabetesVS<- GibbsBvsF(formula= glyhb ~ ., data=diabetes2, n.iter=100000, n.burnin=5000)

summary(diabetesVS)
#A plot of the dimension of the true model, meaning:
#=number of fixed vars+number of factors+number of numerical variables
plot(diabetesVS, option="dimension")
#A joint inclusion plot
plot(diabetesVS, option="joint")

#Now with fixed variables:
diabetesVS2<- GibbsBvsF(formula= glyhb ~ ., null.model= glyhb ~ chol+stab.glu, 
		                   data=diabetes2, n.iter=100000, n.burnin=5000)
											 
											 
#and with fixed factors:
diabetesVS3<- GibbsBvsF(formula= glyhb ~ ., null.model= glyhb ~ chol+stab.glu+location, 
		                   data=diabetes2, n.iter=100000, n.burnin=5000)


}

}
\references{
Garcia-Donato, G. and Martinez-Beneito, M.A.
(2013)<DOI:10.1080/01621459.2012.742443> On sampling strategies in Bayesian
variable selection problems with large model spaces. Journal of the American
Statistical Association, 108: 340-352.

George E. and McCulloch R. (1997) Approaches for Bayesian variable
selection. Statistica Sinica, 7, 339:372.
}
\seealso{
\code{\link[BayesVarSel]{plot.Bvs}} for several plots of the result,
\code{\link[BayesVarSel]{BMAcoeff}} for obtaining model averaged simulations
of regression coefficients and \code{\link[BayesVarSel]{predict.Bvs}} for
predictions. \code{\link[BayesVarSel]{pltltn}} for corrections on estimations for the
situation where p>>n.

\code{\link[BayesVarSel]{Bvs}} for exact
version obtained enumerating all entertained models (recommended when
p<20).
}
\author{
Gonzalo Garcia-Donato and Anabel Forte
}
\keyword{package}
